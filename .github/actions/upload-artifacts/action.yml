name: Upload artifacts
description: Upload artifacts
inputs:
  artifacts-dir:
    description: Directory to store artifacts
    required: true
  target-file:
    description: The path of the target artifact
    required: true
  version:
    description: Version of the artifact
    required: true
  release-to-s3-bucket:
    description: S3 bucket to store released artifacts
    required: true
  aws-access-key-id:
    description: AWS access key id
    required: true
  aws-secret-access-key:
    description: AWS secret access key
    required: true
  aws-region:
    description: AWS region
    required: true
  upload-to-s3:
    description: Upload to S3
    required: false
    default: 'true'
  upload-latest-artifacts:
    description: Upload the latest artifacts to S3
    required: false
    default: 'true'
  upload-max-retry-times:
    description: Max retry times for uploading artifacts to S3
    required: false
    default: "20"
  upload-retry-timeout:
    description: Timeout for uploading artifacts to S3
    required: false
    default: "30" # minutes
  working-dir:
    description: Working directory to upload the artifacts
    required: false
    default: .
runs:
  using: composite
  steps:
    - name: Create artifacts directory
      working-directory: ${{ inputs.working-dir }}
      shell: bash
      run: |
        mkdir -p ${{ inputs.artifacts-dir }} && \
        mv ${{ inputs.target-file }} ${{ inputs.artifacts-dir }}

    # The compressed artifacts will use the following layout:
    # greptime-linux-amd64-pyo3-v0.3.0sha256sum
    # greptime-linux-amd64-pyo3-v0.3.0.tar.gz
    #   greptime-linux-amd64-pyo3-v0.3.0
    #   └── greptime
    - name: Compress artifacts and calculate checksum
      working-directory: ${{ inputs.working-dir }}
      shell: bash
      run: |
        tar -zcvf ${{ inputs.artifacts-dir }}.tar.gz ${{ inputs.artifacts-dir }} && \
        echo $(shasum -a 256 ${{ inputs.artifacts-dir }}.tar.gz | cut -f1 -d' ') > ${{ inputs.artifacts-dir }}.sha256sum

    # Note: The artifacts will be double zip compressed(related issue: https://github.com/actions/upload-artifact/issues/39).
    # However, when we use 'actions/download-artifact@v3' to download the artifacts, it will be automatically unzipped.
    - name: Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: ${{ inputs.artifacts-dir }}
        path: ${{ inputs.working-dir }}/${{ inputs.artifacts-dir }}.tar.gz

    - name: Upload checksum
      uses: actions/upload-artifact@v3
      with:
        name: ${{ inputs.artifacts-dir }}.sha256sum
        path: ${{ inputs.working-dir }}/${{ inputs.artifacts-dir }}.sha256sum

    - name: Upload artifacts to S3
      if: ${{ inputs.upload-to-s3 == 'true' }}
      uses: nick-invision/retry@v2
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws-access-key-id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws-secret-access-key }}
        AWS_DEFAULT_REGION: ${{ inputs.aws-region }}
      with:
        max_attempts: ${{ inputs.upload-max-retry-times }}
        timeout_minutes: ${{ inputs.upload-retry-timeout }}
        # The bucket layout will be:
        # releases/greptimedb
        # ├── v0.1.0
        # │   ├── greptime-darwin-amd64-pyo3-v0.1.0.sha256sum
        # │   └── greptime-darwin-amd64-pyo3-v0.1.0.tar.gz
        # └── v0.2.0
        #    ├── greptime-darwin-amd64-pyo3-v0.2.0.sha256sum
        #    └── greptime-darwin-amd64-pyo3-v0.2.0.tar.gz
        command: |
          cd ${{ inputs.working-dir }} && \
          aws s3 cp \
            ${{ inputs.artifacts-dir }}.tar.gz \
            s3://${{ inputs.release-to-s3-bucket }}/releases/greptimedb/${{ inputs.version }}/${{ inputs.artifacts-dir }}.tar.gz && \
          aws s3 cp \
            ${{ inputs.artifacts-dir }}.sha256sum \
            s3://${{ inputs.release-to-s3-bucket }}/releases/greptimedb/${{ inputs.version }}/${{ inputs.artifacts-dir }}.sha256sum

    - name: Upload latest artifacts to S3
      if: ${{ inputs.upload-to-s3 == 'true' && inputs.upload-latest-artifacts == 'true' }} # We'll also upload the latest artifacts to S3 in the scheduled and formal release.
      uses: nick-invision/retry@v2
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws-access-key-id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws-secret-access-key }}
        AWS_DEFAULT_REGION: ${{ inputs.aws-region }}
      with:
        max_attempts: ${{ inputs.upload-max-retry-times }}
        timeout_minutes: ${{ inputs.upload-retry-timeout }}
        command: |
          cd ${{ inputs.working-dir }} && \
          aws s3 cp \
            ${{ inputs.artifacts-dir }}.tar.gz \
            s3://${{ inputs.release-to-s3-bucket }}/releases/greptimedb/latest/${{ inputs.artifacts-dir }}.tar.gz && \
          aws s3 cp \
            ${{ inputs.artifacts-dir }}.sha256sum \
            s3://${{ inputs.release-to-s3-bucket }}/releases/greptimedb/latest/${{ inputs.artifacts-dir }}.sha256sum
