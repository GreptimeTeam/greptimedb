CREATE TABLE numbers_input_basic (
    number INT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY(number),
    TIME INDEX(ts)
);

Affected Rows: 0

CREATE FLOW test_numbers_basic
SINK TO out_num_cnt_basic
AS
SELECT sum(number) FROM numbers_input_basic GROUP BY tumble(ts, '1 second', '2021-07-01 00:00:00');

Affected Rows: 0

-- TODO(discord9): confirm if it's necessary to flush flow here?
-- because flush_flow result is at most 1
admin flush_flow('test_numbers_basic');

+----------------------------------------+
| ADMIN flush_flow('test_numbers_basic') |
+----------------------------------------+
| 0                                      |
+----------------------------------------+

-- SQLNESS ARG restart=true
INSERT INTO numbers_input_basic
VALUES
    (20, "2021-07-01 00:00:00.200"),
    (22, "2021-07-01 00:00:00.600");

Affected Rows: 2

admin flush_flow('test_numbers_basic');

+----------------------------------------+
| ADMIN flush_flow('test_numbers_basic') |
+----------------------------------------+
| 1                                      |
+----------------------------------------+

SELECT "SUM(numbers_input_basic.number)", window_start, window_end FROM out_num_cnt_basic;

+---------------------------------+---------------------+---------------------+
| SUM(numbers_input_basic.number) | window_start        | window_end          |
+---------------------------------+---------------------+---------------------+
| 42                              | 2021-07-01T00:00:00 | 2021-07-01T00:00:01 |
+---------------------------------+---------------------+---------------------+

admin flush_flow('test_numbers_basic');

+----------------------------------------+
| ADMIN flush_flow('test_numbers_basic') |
+----------------------------------------+
| 0                                      |
+----------------------------------------+

INSERT INTO numbers_input_basic
VALUES
    (23,"2021-07-01 00:00:01.000"),
    (24,"2021-07-01 00:00:01.500");

Affected Rows: 2

admin flush_flow('test_numbers_basic');

+----------------------------------------+
| ADMIN flush_flow('test_numbers_basic') |
+----------------------------------------+
| 1                                      |
+----------------------------------------+

-- note that this quote-unquote column is a column-name, **not** a aggregation expr, generated by datafusion
SELECT "SUM(numbers_input_basic.number)", window_start, window_end FROM out_num_cnt_basic;

+---------------------------------+---------------------+---------------------+
| SUM(numbers_input_basic.number) | window_start        | window_end          |
+---------------------------------+---------------------+---------------------+
| 42                              | 2021-07-01T00:00:00 | 2021-07-01T00:00:01 |
| 47                              | 2021-07-01T00:00:01 | 2021-07-01T00:00:02 |
+---------------------------------+---------------------+---------------------+

DROP FLOW test_numbers_basic;

Affected Rows: 0

DROP TABLE numbers_input_basic;

Affected Rows: 0

DROP TABLE out_num_cnt_basic;

Affected Rows: 0

-- test distinct
CREATE TABLE distinct_basic (
    number INT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY(number),
    TIME INDEX(ts)
);

Affected Rows: 0

CREATE FLOW test_distinct_basic
SINK TO out_distinct_basic
AS
SELECT DISTINCT number as dis FROM distinct_basic;

Affected Rows: 0

-- TODO(discord9): confirm if it's necessary to flush flow here?
-- because flush_flow result is at most 1
admin flush_flow('test_distinct_basic');

+-----------------------------------------+
| ADMIN flush_flow('test_distinct_basic') |
+-----------------------------------------+
| 0                                       |
+-----------------------------------------+

-- SQLNESS ARG restart=true
INSERT INTO distinct_basic
VALUES
    (20, "2021-07-01 00:00:00.200"),
    (22, "2021-07-01 00:00:00.600");

Affected Rows: 2

admin flush_flow('test_distinct_basic');

+-----------------------------------------+
| ADMIN flush_flow('test_distinct_basic') |
+-----------------------------------------+
| 1                                       |
+-----------------------------------------+

SELECT dis FROM out_distinct_basic;

+-----+
| dis |
+-----+
| 20  |
| 22  |
+-----+

admin flush_flow('test_distinct_basic');

+-----------------------------------------+
| ADMIN flush_flow('test_distinct_basic') |
+-----------------------------------------+
| 0                                       |
+-----------------------------------------+

INSERT INTO distinct_basic
VALUES
    (23,"2021-07-01 00:00:01.000"),
    (24,"2021-07-01 00:00:01.500");

Affected Rows: 2

admin flush_flow('test_distinct_basic');

+-----------------------------------------+
| ADMIN flush_flow('test_distinct_basic') |
+-----------------------------------------+
| 1                                       |
+-----------------------------------------+

-- note that this quote-unquote column is a column-name, **not** a aggregation expr, generated by datafusion
SELECT dis FROM out_distinct_basic;

+-----+
| dis |
+-----+
| 20  |
| 22  |
| 23  |
| 24  |
+-----+

DROP FLOW test_distinct_basic;

Affected Rows: 0

DROP TABLE distinct_basic;

Affected Rows: 0

DROP TABLE out_distinct_basic;

Affected Rows: 0

-- test interprete interval
CREATE TABLE numbers_input_basic (
    number INT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY(number),
    TIME INDEX(ts)
);

Affected Rows: 0

create table out_num_cnt_basic (
    number INT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP TIME INDEX);

Affected Rows: 0

CREATE FLOW filter_numbers_basic SINK TO out_num_cnt_basic AS SELECT INTERVAL '1 day 1 second', INTERVAL '1 month 1 day 1 second', INTERVAL '1 year 1 month' FROM numbers_input_basic where number > 10;

Affected Rows: 0

SHOW CREATE FLOW filter_numbers_basic;

+----------------------+----------------------------------------------------------------------------------------------------------------------------------------------+
| Flow                 | Create Flow                                                                                                                                  |
+----------------------+----------------------------------------------------------------------------------------------------------------------------------------------+
| filter_numbers_basic | CREATE OR REPLACE FLOW IF NOT EXISTS filter_numbers_basic                                                                                    |
|                      | SINK TO out_num_cnt_basic                                                                                                                    |
|                      | AS SELECT INTERVAL '1 day 1 second', INTERVAL '1 month 1 day 1 second', INTERVAL '1 year 1 month' FROM numbers_input_basic WHERE number > 10 |
+----------------------+----------------------------------------------------------------------------------------------------------------------------------------------+

drop flow filter_numbers_basic;

Affected Rows: 0

drop table out_num_cnt_basic;

Affected Rows: 0

drop table numbers_input_basic;

Affected Rows: 0

CREATE TABLE bytes_log (
    byte INT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- event time
    TIME INDEX(ts)
);

Affected Rows: 0

-- TODO(discord9): remove this after auto infer table's time index is impl
CREATE TABLE approx_rate (
    rate DOUBLE,
    time_window TIMESTAMP,
    update_at TIMESTAMP,
    TIME INDEX(time_window)
);

Affected Rows: 0

CREATE FLOW find_approx_rate
SINK TO approx_rate
AS
SELECT (max(byte) - min(byte))/30.0 as rate, date_bin(INTERVAL '30 second', ts) as time_window from bytes_log GROUP BY time_window;

Affected Rows: 0

INSERT INTO bytes_log VALUES
(101, '2025-01-01 00:00:01'),
(300, '2025-01-01 00:00:29');

Affected Rows: 2

admin flush_flow('find_approx_rate');

+--------------------------------------+
| ADMIN flush_flow('find_approx_rate') |
+--------------------------------------+
| 1                                    |
+--------------------------------------+

SELECT rate, time_window FROM approx_rate;

+-------------------+---------------------+
| rate              | time_window         |
+-------------------+---------------------+
| 6.633333333333334 | 2025-01-01T00:00:00 |
+-------------------+---------------------+

INSERT INTO bytes_log VALUES
(450, '2025-01-01 00:00:32'),
(500, '2025-01-01 00:00:37');

Affected Rows: 2

admin flush_flow('find_approx_rate');

+--------------------------------------+
| ADMIN flush_flow('find_approx_rate') |
+--------------------------------------+
| 1                                    |
+--------------------------------------+

SELECT rate, time_window FROM approx_rate;

+--------------------+---------------------+
| rate               | time_window         |
+--------------------+---------------------+
| 6.633333333333334  | 2025-01-01T00:00:00 |
| 1.6666666666666667 | 2025-01-01T00:00:30 |
+--------------------+---------------------+

DROP TABLE bytes_log;

Affected Rows: 0

DROP FLOW find_approx_rate;

Affected Rows: 0

DROP TABLE approx_rate;

Affected Rows: 0

